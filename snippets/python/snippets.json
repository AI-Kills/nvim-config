{
  "subprocess": {
    "prefix": "subp",
    "body": [
      "try:",
      "\tsubprocess.run(",
      "\t\t[",
      "\t\t\t\"git\",",
      "\t\t\t\"merge\", f\"{b}\"",
      "\t\t],",
      "\t\tcapture_output=True,",
      "\t\tcheck=True,",
      "\t\ttext=True",
      "\t)",
      "",
      "except subprocess.CalledProcessError as e:",
      "\tprint(f\"❌ Error merging branch develop on {b}: {e}\")"
    ],
    "description": "execute a subprocess with try except error handling"
  },
  "script_dir": {
    "prefix": "dir",
    "body": [
      "script_dir = os.path.dirname(os.path.abspath(__file__))"
    ],
    "description": "absolute path to the parent dir of the dir of this file"
  },
  "import_registry": {
    "prefix": "reg",
    "body": [
      "from src.registry import *"
    ],
    "description": "import the registry for dependency injection end simplicity"
  },
  "langgraph_imports": {
    "prefix": "lgi",
    "body": [
      "from typing import Dict, TypedDict",
      "import os",
      "import sys",
      "sys.path.append(os.path.dirname(os.path.dirname(os.path.abspath(__file__))))",
      "from langgraph.graph import StateGraph",
      "from utils.visualize_graph import visualize_graph",
      "from langchain.chat_models import init_chat_model"
    ],
    "description": "signature of a node function"
  },
  "langgraph_node_function": {
    "prefix": "node",
    "body": [
      "def ${1:node_name}(Σ: AgentState) -> AgentState:",
      "Γ.add_node(${1:node_name})"
    ],
    "description": "signature of a node function"
  },
  "with open read": {
    "prefix": "wor",
    "body": [
      "with open(${1:file_path}, 'r') as ${2:f}:",
      "\t${3:# file operations}"
    ],
    "description": "With statement for reading files"
  },
  "with open write": {
    "prefix": "wow",
    "body": [
      "with open(${1:file_path}, 'w') as ${2:f}:",
      "\t${3:# file operations}"
    ],
    "description": "With statement for writing files"
  },
  "write json file": {
    "prefix": "wjf",
    "body": [
      "with open(${1:path}, 'w', encoding='utf-8') as f:",
      "\tjson.dump(${2:structure}, f, ensure_ascii=False, indent=2)"
    ],
    "description": "Write a json file"
  },
  "patate debug": {
    "prefix": "ptt",
    "body": [
      "print(\"🥔🥔🥔\", ${1:var})"
    ],
    "description": "patate debug"
  },
  "langchain messages": {
    "prefix": "lcmess",
    "body": [
      "from langchain_core.messages import HumanMessage, SystemMessage"
    ],
    "description": "import langchain messages objects"
  },
  "lambda": {
    "prefix": "lmb",
    "body": [
      "lambda x: ${1:x}"
    ],
    "description": "lambda functiontion"
  },
  "typing": {
    "prefix": "ty",
    "body": "from typing import List, Dict, Optional, Union, Tuple, Any, Callable",
    "description": "import common data structures"
  },
  "Import common data libraries": {
    "prefix": "impdata",
    "body": [
      "import numpy as np",
      "import pandas as pd",
      "import matplotlib.pyplot as plt",
      "import seaborn as sns"
    ],
    "description": "Import common data science libraries"
  },
  "Class definition": {
    "prefix": "cldef",
    "body": [
      "class ${1:ClassName}:",
      "\t\"\"\"${2:Class docstring}\"\"\"",
      "\t",
      "\tdef __init__(self, ${3:parameters}):",
      "\t\t\"\"\"Initialize the ${1:ClassName} instance.",
      "\t\t",
      "\t\tArgs:",
      "\t\t\t${4:param_name}: ${5:param_description}",
      "\t\t\"\"\"",
      "\t\t${6:pass}",
      "\t",
      "\tdef ${7:method_name}(self, ${8:parameters}):",
      "\t\t\"\"\"${9:Method docstring}",
      "\t\t",
      "\t\tArgs:",
      "\t\t\t${10:param_name}: ${11:param_description}",
      "\t\t",
      "\t\tReturns:",
      "\t\t\t${12:return_description}",
      "\t\t\"\"\"",
      "\t\t${13:pass}"
    ],
    "description": "Class definition with methods and docstrings"
  },
  "Try except": {
    "prefix": "tryex",
    "body": [
      "try:",
      "\t${1:# code that might raise an exception}",
      "except ${2:Exception} as ${3:e}:",
      "\t${4:# handle the exception}",
      "\tprint(f\"Error: {${3:e}}\")"
    ],
    "description": "Try-except block"
  },
  "Try except else finally": {
    "prefix": "tryexef",
    "body": [
      "try:",
      "\t${1:# code that might raise an exception}",
      "except ${2:Exception} as ${3:e}:",
      "\t${4:# handle the exception}",
      "\tprint(f\"Error: {${3:e}}\")",
      "else:",
      "\t${5:# code to run if no exception}",
      "finally:",
      "\t${6:# code to run always}"
    ],
    "description": "Try-except-else-finally block"
  },
  "LangChain prompt template": {
    "prefix": "lcpt",
    "body": [
      "from langchain.prompts import PromptTemplate",
      "",
      "# Define a prompt template",
      "prompt_template = PromptTemplate.from_template(",
      "\"\"\"",
      "${1:prompt_text}",
      "Formato richiesto: {${2:format_instructions}}",
      "Input JSON: {${3:input_json}}",
      "\"\"\"",
      ")"
    ],
    "description": "Create a LangChain prompt template"
  },
  "LangChain model": {
    "prefix": "lcm",
    "body": [
      "from langchain.chat_models import init_chat_model",
      "llm = init_chat_model(\"gpt-4o-mini\", model_provider=\"openai\", temperature=0.0)"
    ],
    "description": "Initialize a LangChain model"
  },
  "Pydantic model": {
    "prefix": "pydm",
    "body": [
      "from pydantic import BaseModel, Field",
      "from typing import Optional",
      "class ${1:Model}(BaseModel):",
      "\t${2:field_name}: ${3:field_type} = Field(..., description=\"${4:Field description}\")"
    ],
    "description": "Create a Pydantic model"
  },
  "LangChain pydantic parser": {
    "prefix": "lcpp",
    "body": [
      "from langchain.output_parsers import PydanticOutputParser",
      "",
      "${parser} = PydanticOutputParser(pydantic_object=${1:model_name})"
    ],
    "description": "Create a Pydantic output parser for LangChain"
  },
  "LangChain  basic chain": {
    "prefix": "lcc",
    "body": [
      "from langchain.output_parsers import PydanticOutputParser",
      "from langchain.chat_models import init_chat_model",
      "from langchain.prompts import PromptTemplate",
      "",
      "prompt = PromptTemplate.from_template(",
      "\"\"\"",
      "prompt_text",
      "Formato richiesto: {format_instructions}",
      "Input JSON: {input_json}",
      "\"\"\"",
      ")",
      "llm = init_chat_model(\"gpt-4o-mini\", model_provider=\"openai\", temperature=0.0)",
      "${parser} = PydanticOutputParser(pydantic_object=model)",
      "similarity_llm = prompt | llm | parser"
    ],
    "description": "Create a Pydantic output parser for LangChain"
  },
  "LangChain RAG setup": {
    "prefix": "lcrag",
    "body": [
      "from langchain.document_loaders import ${1:TextLoader}",
      "from langchain.text_splitter import RecursiveCharacterTextSplitter",
      "from langchain.embeddings import OpenAIEmbeddings",
      "from langchain.vectorstores import Chroma",
      "from langchain.chains import RetrievalQA",
      "from langchain.llms import OpenAI",
      "",
      "# 1. Load documents",
      "loader = ${1:TextLoader}(\"${2:path/to/document}\")",
      "documents = loader.load()",
      "",
      "# 2. Split documents into chunks",
      "text_splitter = RecursiveCharacterTextSplitter(",
      "\tchunk_size=${3:1000},",
      "\tchunk_overlap=${4:100}",
      ")",
      "chunks = text_splitter.split_documents(documents)",
      "",
      "# 3. Create embeddings and vectorstore",
      "embeddings = OpenAIEmbeddings()",
      "vectorstore = Chroma.from_documents(chunks, embeddings)",
      "",
      "# 4. Create a retrieval chain",
      "qa_chain = RetrievalQA.from_chain_type(",
      "\tllm=OpenAI(),",
      "\tchain_type=\"stuff\",",
      "\tretriever=vectorstore.as_retriever()",
      ")",
      "",
      "# 5. Ask a question",
      "result = qa_chain({\"query\": \"${5:Your question about the documents?}\"})"
    ],
    "description": "Set up a Retrieval Augmented Generation (RAG) system with LangChain"
  },
  "Import pathlib": {
    "prefix": "pathlibi",
    "body": [
      "from pathlib import Path"
    ],
    "description": "Import Path from pathlib"
  },
  "main": {
    "prefix": "main",
    "body": [
      "if __name__ == '__main__':"
    ],
    "description": "call a script directly"
  }
}

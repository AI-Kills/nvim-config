{
  "subprocess": {
    "prefix": "subp",
    "body": [
      "try:",
      "\tsubprocess.run(",
      "\t\t[",
      "\t\t\t\"git\",",
      "\t\t\t\"merge\", f\"{b}\"",
      "\t\t],",
      "\t\tcapture_output=True,",
      "\t\tcheck=True,",
      "\t\ttext=True",
      "\t)",
      "",
      "except subprocess.CalledProcessError as e:",
      "\tprint(f\"âŒ Error merging branch develop on {b}: {e}\")"
    ],
    "description": "execute a subprocess with try except error handling"
  },
  "script_dir": {
    "prefix": "dir",
    "body": [
      "script_dir = os.path.dirname(os.path.abspath(__file__))"
    ],
    "description": "absolute path to the parent dir of the dir of this file"
  },
  "import_registry": {
    "prefix": "reg",
    "body": [
      "from registry import *"
    ],
    "description": "import the registry for dependency injection end simplicity"
  },
  "langgraph_node_function": {
    "prefix": "Î“an",
    "body": [
      "def ${1:node_name}(state: GraphState) -> GraphState:",
      "\treturn state",
      "_g.add_node(\"${1:node_name}\", ${1:node_name})"
    ],
    "description": "create a node"
  },
  "pytorch": {
    "prefix": "Î¤",
    "body": "torch",
    "description": "pytorch"
  },
  "langgraph_init": {
    "prefix": "Î“ini",
    "body": [
      "class GraphState(TypedDict):",
      "\tmessage: str",
      "\tmetadata: dict",
      "\n_g = StateGraph(GraphState)",
      "\n",
      "def _start(state: GraphState) -> GraphState:",
      "\tprint(\"start node\")",
      "\treturn state",
      "_g.add_node(\"_start\", _start)",
      "_g.add_edge(START, \"_start\")",
      "\n",
      "def _end(state: GraphState) -> GraphState:",
      "\tprint(\"end node\")",
      "\treturn state",
      "_g.add_node(\"_end\", _end)",
      "_g.add_edge(\"_end\", END)",
      "${1:logic}",
      "g=_g.compile()",
      "show_mermaid(g)"
    ],
    "description": "init the graph: define the GraphState"
  },
  "langgraph_add_edge": {
    "prefix": "Î“ae",
    "body": [
      "_g.add_edge(\"${1:origin_node}\", \"${2:destination_node}\")"
    ],
    "description": "add an edge to the state graph"
  },
  "define a function": {
    "prefix": "fnd",
    "body": [
      "def ${1:function_name}():"
    ],
    "description": "start the definition of a functiontion"
  },
  "with open read": {
    "prefix": "wor",
    "body": [
      "with open(${1:file_path}, 'r') as ${2:f}:",
      "\t${3:# file operations}"
    ],
    "description": "With statement for reading files"
  },
  "with open write": {
    "prefix": "wow",
    "body": [
      "with open(${1:file_path}, 'w') as ${2:f}:",
      "\t${3:# file operations}"
    ],
    "description": "With statement for writing files"
  },
  "write json file": {
    "prefix": "wjf",
    "body": [
      "with open(${1:path}, 'w', encoding='utf-8') as f:",
      "\tjson.dump(${2:structure}, f, ensure_ascii=False, indent=2)"
    ],
    "description": "Write a json file"
  },
  "patate debug": {
    "prefix": "ptt",
    "body": [
      "print(\"ðŸ¥”ðŸ¥”ðŸ¥”\", ${1:var})"
    ],
    "description": "patate debug"
  },
  "langchain messages": {
    "prefix": "lcmess",
    "body": [
      "from langchain_core.messages import HumanMessage, SystemMessage"
    ],
    "description": "import langchain messages objects"
  },
  "lambda": {
    "prefix": "lmb",
    "body": [
      "lambda x: ${1:x}"
    ],
    "description": "lambda functiontion"
  },
  "typing": {
    "prefix": "ty",
    "body": "from typing import List, Dict, Optional, Union, Tuple, Any, Callable",
    "description": "import common data structures"
  },
  "Import common data libraries": {
    "prefix": "impdata",
    "body": [
      "import numpy as np",
      "import pandas as pd",
      "import matplotlib.pyplot as plt",
      "import seaborn as sns"
    ],
    "description": "Import common data science libraries"
  },
  "Class definition": {
    "prefix": "cldef",
    "body": [
      "class ${1:ClassName}:",
      "\t\"\"\"${2:Class docstring}\"\"\"",
      "\t",
      "\tdef __init__(self, ${3:parameters}):",
      "\t\t\"\"\"Initialize the ${1:ClassName} instance.",
      "\t\t",
      "\t\tArgs:",
      "\t\t\t${4:param_name}: ${5:param_description}",
      "\t\t\"\"\"",
      "\t\t${6:pass}",
      "\t",
      "\tdef ${7:method_name}(self, ${8:parameters}):",
      "\t\t\"\"\"${9:Method docstring}",
      "\t\t",
      "\t\tArgs:",
      "\t\t\t${10:param_name}: ${11:param_description}",
      "\t\t",
      "\t\tReturns:",
      "\t\t\t${12:return_description}",
      "\t\t\"\"\"",
      "\t\t${13:pass}"
    ],
    "description": "Class definition with methods and docstrings"
  },
  "Try except": {
    "prefix": "tryex",
    "body": [
      "try:",
      "\t${1:# code that might raise an exception}",
      "except ${2:Exception} as ${3:e}:",
      "\t${4:# handle the exception}",
      "\tprint(f\"Error: {${3:e}}\")"
    ],
    "description": "Try-except block"
  },
  "Try except else finally": {
    "prefix": "tryexef",
    "body": [
      "try:",
      "\t${1:# code that might raise an exception}",
      "except ${2:Exception} as ${3:e}:",
      "\t${4:# handle the exception}",
      "\tprint(f\"Error: {${3:e}}\")",
      "else:",
      "\t${5:# code to run if no exception}",
      "finally:",
      "\t${6:# code to run always}"
    ],
    "description": "Try-except-else-finally block"
  },
  "LangChain prompt template": {
    "prefix": "lcpt",
    "body": [
      "from langchain.prompts import PromptTemplate",
      "",
      "# Define a prompt template",
      "prompt_template = PromptTemplate.from_template(",
      "\"\"\"",
      "${1:prompt_text}",
      "Formato richiesto: {${2:format_instructions}}",
      "Input JSON: {${3:input_json}}",
      "\"\"\"",
      ")"
    ],
    "description": "Create a LangChain prompt template"
  },
  "LangChain model": {
    "prefix": "Î›llm",
    "body": [
      "llm = init_chat_model(\"gpt-4o-mini\", model_provider=\"openai\", temperature=0.0)"
    ],
    "description": "Initialize a LangChain model"
  },
  "Pydantic model": {
    "prefix": "Î›pm",
    "body": [
      "class ${1:Model}(BaseModel):",
      "\t${2:field_name}: ${3:field_type} = Field(..., description=\"${4:Field description}\")"
    ],
    "description": "Create a Pydantic model"
  },
  "LangChain  basic chain": {
    "prefix": "Î›c",
    "body": [
      "prompt = PromptTemplate.from_template(",
      "\"\"\"",
      "prompt_text",
      "Formato richiesto: {format_instructions}",
      "Input JSON: {input_json}",
      "\"\"\"",
      ")",
      "llm = init_chat_model(\"gpt-4o-mini\", model_provider=\"openai\", temperature=0.0)",
      "parser = PydanticOutputParser(pydantic_object=model)",
      "similarity_llm = prompt | llm | parser"
    ],
    "description": "Create a Pydantic output parser for LangChain"
  },
  "main": {
    "prefix": "Îœ",
    "body": [
      "if __name__ == '__main__':"
    ],
    "description": "call a script directly"
  }
}
